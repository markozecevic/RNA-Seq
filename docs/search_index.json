[["index.html", "Analiza RNA-Seq podataka Podešavanja", " Analiza RNA-Seq podataka marko.zecevic@sbgenomics.com 2023-04-20 Podešavanja Linux okruženje sa instaliranim neophodnim paketima i RStudiom je dokerizovano i postavljeno na Docker Hub. Nakon instalacije Docker-a, potrebno je odraditi pull (~4.3 GB download). docker pull markoz/rnastudio:2021 Opciono, možete klonirati GitHub repo sa meterijalima. git clone git@github.com:markozecevic/RNA-Seq.git Kada u lokalu imate i Docker image i materijale, pokrenućete Docker container komandom (potrebno je zameniti /putanja/do/repozitorijuma/RNA-Seq sa pravom putanjom kloniranog repozitorijuma u vašem lokalnom sistemu): docker run -e PASSWORD=etf -p 8787:8787 -v /putanja/do/repozitorijuma/RNA-Seq:/home/rstudio/materijali -e ROOT=TRUE markoz/rnastudio:2021 U browseru otvoriti http://localhost:8787/ (user: “rstudio, pass:”etf\"). Sledeće komande će podesiti radni folder i izrenderovati materijale, ali ohrabrujemo vas da primenite interaktivniji pristup, i izvršavate ćeliju po ćeliju: setwd(&quot;~/materijali&quot;) bookdown::render_book(&quot;index.Rmd&quot;, &quot;bookdown::gitbook&quot;) "],["uvod.html", "1 Uvod 1.1 DNK i RNK 1.2 Centralna dogma molekularne biologije 1.3 Vrste RNK 1.4 Alternativno splajsovanje 1.5 Ciljevi proučavanja RNK 1.6 RNK sekvenciranje 1.7 DNK mikročip (microarray) 1.8 Literatura", " 1 Uvod 1.1 DNK i RNK Dezoksiribonukleinska kiselina (DNK) je molekul nosilac genetskih informacija. Kod eukariotskih organizama, najveći broj ovih molekula nalazi se u jedru ćelije, a manji broj u organelama kao što su mitohondrije i hloroplasti (u biljkama). Dugački, vlaknasti molekul DNK nazivamo hromozom. Kod čoveka je hromozom dvostruki, spiralno uvijeni niz od 50 do 250 miliona nukleotida. Jedan segment tog niza koji kodira molekul ribonukleinske kiseline (RNK) naziva se gen, a ceo skup genetskih instrukcija koje nosi neki organizam - genom. Gen je funkcionalna jedinica genoma, a ljudski genom sadrži oko 20,000 gena. Spomenuli smo da su DNK (kao i RNK) molekuli - nizovi nukleotida. Nukleotidi su monomeri nukleinskih kiselina i sastoje se od po jednog molekula: Šećera pentoze: dezoksiriboze (u DNK) ili riboze (u RNK); Fosforne kiseline; Azotne baze: purinske (adenin - A ili guanin - G) ili pirimidinske (citozin - C, timin - T ili uracil - U). Baze u sastavu DNK su A,G,C,T dok kod RNK U zamenjuje T. Hemijska struktura nukleotida [“Nucleic acids”, Figure 3.31, OpenStax College, Biology 2e | CC BY 4.0]. I dezoksiriboza i riboza sadrže pet ugljenikovih atoma. U RNK i DNK molekulima, šećeri susednih nukleotida su međusobno povezani fosfatnim grupama koje stvaraju fosfodiestarsku vezu između trećeg (3’) i petog (5’) ugljenikovog atoma. Pored šećera i fosfatne grupe, nukleotidi sadrže i jednu azotnu bazu koja predstavlja varijabilni deo. Redosled baza u lancu kodira naslednu informaciju. Svaka baza na jednom lancu spojena je vodoničnim vezama sa komplementarnom bazom na naspramnom lancu. A se sparuje samo sa T i to sa dve vodonične veze, dok se C se sparuje samo sa G sa tri vodonične veze. Vodonične veze se mogu raskinuti i lako ponovo formirati što se stalno i dešava kao posledica raznih procesa u ćeliji (npr. prilikom transkripcije ili replikacije DNK). Dve vodonične veze (A-T) se lakše raskidaju od tri (C-G). Hemijska struktura DNK [Madeleine Price Ball | CC0]. Uz pomoć alfabeta nukleotidnih baza mozemo zapisati jedan segment DNK lanca kao: ACCTGACGTAA. Samo jedan od dva DNK lanca kodira RNK, tako da se genetički kod zapisuje kao sekvenca nukleotida (baza), a ne baznih parova. Prema konvenciji, DNK ili RNK sekvenca se zapisuje u pravcu od 5’ ka 3’. Svaka ćelija našeg organizma sadrzi praktično istu DNK (osim u haploidnim polnim ćelijama), ali neke od tih ćelija vrše potpuno različite funkcije. Folikularna ćelija štitaste žlezde i glatka mišićna ćelija očigledno moraju imaju drastično različit metabolizam, ali kako kada je osnovni genetski kod u obe ćelije isti? 1.2 Centralna dogma molekularne biologije Da bi ćelija ostvarila biohemijske procese neophodne za održavanje života i obavljanje svoje specijalizovane funkcije, ona mora sintetisati proteine. Proteini su katalizatori biohemijskih procesa u ćelijama, a obavljaju još niz važnih uloga uključujući strukturnu, regulatornu, transportnu itd. Funkcija proteina određena je njegovom strukturom, a nju određuje informacija zapisana u genima. Protok ovih informacija opisan je centralnom dogmom molekularne biologije, koja bi u (pre)pojednostavljenom obliku mogla da glasi: “DNK određuje RNK, RNK određuje proteine, proteini grade nas.” Centralna dogma molekularne biologije definiše osnovni smer protoka biološke informacije. U ovom toku informacije razlikujemo tri glavna procesa: Informacija sadržana u segmentu DNK niza se može kopirati u RNK kroz proces koji nazivamo transkripcija uz posredstvo enzima RNK-polimeraze. Informacijska RNK (iRNK; eng: messenger RNA - mRNA) nastaje od prekurzorne iRNK (koja je produkt transkripcije) procesom splajsovanja, u kojem se uklanjaju tzv. intronske regije (introni). Translacijom nazivan proces sintetizovanja proteina nizanjem amino kiselina po iRNK šablonu. Translacija se obavlja unutar ribozoma - organele sačinjene od ribozomalne RNK (rRNK) i proteina. 1.2.1 Transkripcija Promoterski region je segment duzine 100-1000 baza koji se nalazi uz gen na 5’ strani. Ovde se inicijalno vezuje RNK-polimeraza i zapocinje proces transkripcije. Pojacivaci (enhancers) mogu biti i udaljeni od pocetka gena i locirani u bilo kom pravcu. Na njih se vezuju transcription faktori koji interaguju sa RNK-polimerazom i tako povećavaju šansu da dođe to transkripcije. Postoje i regioni koje imaju suprotnu regulatornu ulogu. 1.2.2 Splajsovanje Prvi proizvod transkripcije je takozvani primarni transkript odnosno vec pomenuta prekurzorna iRNK. Ovo je doslovno prepisana sekvenca kodirajuceg lanca od pocetka do kraja gena, osim sto je svako T zamenjeno sa U1. U procesu formiranja zrele iRNK intronske sekvence bivaju uklonjene. 1.2.3 Translacija Sinteza proteina se obavlja u ribozomima u procesu u kojem se kod zapisan sa cetiri nukleinske kiseline prevodi u kod 20 aminokiselina koje se nizu po odredjenom obrascu. Ulogu prevodioca igraju tRNK molekuli koji jednim svojim krajem prepoznaju odgovarajuci (komplementaran) kodon2 na iRNK, a na drugom kraju nose odgovarajuću aminokiselinu. Standardni genetski kod [“The genetic code”, Figure 15.4, OpenStax College, Biology | CC BY 3.0]. DEFINISI OKVIR CITANJA!!!! I PREBACI FUTNOTU OVDE NEGDE UTR (od UnTranslated Region) su netranslirajuci (koji ne kodiraju aminokiseline, tj nalaze se van okvira citanja) regioni bogati regulatornim sekvencama koje uticu na regulaciju translacije iRNK kojoj pripadaju. 1.3 Vrste RNK Spomenuli smo ribozome i tRNK, pa je vreme da napomenemo da postoji vise vrsta RNK molekula: informacijska (iRNK), transportna RNK (tRNK), ribozomalna RNK (rRNK), kratka i duga nekodirajuca RNK (nkRNK). Samo iRNK kodira proteine, a broj danas poznatih nekodirajucih gena veci je od broja kodirajucih. Navodeci centralnu dogmu molekularne biologije, definisali smo osnovni smer protoka biološke informacije. Ovde se pod pojmom informacije podrazumeva kod predstavljen nizom DNK nukleotida koji se prevodi u niz RNK nukleotida i najzad iz niza RNK nukleotida u niz aminokiselina polipeptidnog lanca. Zato je ovaj tok informacije prikazan kao jednosmeran. Naravno, proces sinteze proteina mora biti regulisan jer aktivnost određenog gena varira u vremenu i od ćelije do ćelije, pa nekakva povratna sprega postoji. Ona se formira uz pomoc velikog broja nekodirajucih gena koji vrse vazne regulatorne funkcije i tako ucestvuju u procesu ekspresije gena. Ovi geni osim procesa transkripcije i translacije regulisu i jos jedan izuzetno vazan proces - replikaciju DNK. Informaciona RNK zastupljena je sa oko ~5% u ćelijama sisara, ribozomalna RNK ~80%, transportna RNK (učestvuje u procesu translacije) ~15% … 1.4 Alternativno splajsovanje Od jednog gena, nakon slajsinga, mogu nastati razlicite varijante iRNK molekula koje nazivamo transkripti (ili izoforme). Ekvivalentno relaciji gen-genom, ‘katalog’ svih mogućih transkripata zovemo transkritom. Alternativno splajsovanje je proces kojim od prekursorkse iRNK koji je doslovno prepisan DNK kod nastaje iRNK koji će kodirati protein. Splajsovanjem dolazi do odstranjivanja intronskih regija (introna), ali se isto može desiti i pojedinim eksonima. Rezultujući različiti mRNA molekuli mogu biti translirani u različite proteine, odnosno - jedan gen može da kodira više proteina. Alternativno splajsovanje se javlja kao normalna pojava kod eukariota, gde znatno povećava raznovrsnost proteina. Kod ljudi preko 80% gena su alternativno splajsovani. Brojni modovi alternativnog splajsovanja su uočeni, od kojih najčešći jeste preskakanje egzona. U tom modu, pojedini egzon može biti uključen u iRNK pod nekim uslovima ili u pojedinim tkivima, i izostavljen iz iRNK u drugim. Ovo je nešto što će otežati problem mapiranja na referentni genom. Aligner mora biti ‘splice aware’! 1.5 Ciljevi proučavanja RNK Zašto merimo ekspresiju gena? Proteini (belančevine) su krajnji proizvod procesa opisanog centralnom dogmom molekularne biologije i predstavljaju za živi sistem najznačajnije organske molekule. Osim što izgrađuju ćeliju i njene delove, proteini obavljaju i sve osnovne funkcije u organizmu. Shodno tome, ako analiziramo status i funkcionalnost podaci o prisutnosti i relativnoj zastupljenosti određenih proteina su najinformativniji u analizi statusa i funkcionalnosti neke celije, tkiva ili organa. Nazalost, i dalje je izuzetno komplikovano direktno izmeriti relativnu zastupljenost određenog proteina u uzorku. Trenutno raspoložive tehnologije su takve da je neuporedivo lakše (i jeftinije) izmeriti relativnu zastupljenost iRNK molekula koji kodira taj protein. Because gene expression correlates with protein expression! Even though nearly every cell in an organism’s body contains the same set of genes, only a fraction of these genes are used in any given cell at any given time. It is this carefully controlled pattern of what is called “gene expression” that makes a liver cell different from a muscle cell, and a healthy cell different from a cancer cell. By measuring gene expression, we can identify active and inactive genes in a cell or tissue. This knowledge is important for drug discovery and creating diagnostic tests. U širem smislu, možemo razlikovati dva pristupa analizi RNK: Kvalitativni pristup, koji za cilj ima rekonstrukciju transkriptoma - kompletnog seta transkripata gena prisutnih u ćelijama uzorka; Kvantitativni pristup, koji za cilj ima estimaciju nivoa ekspresije gena tj. transkripata. 1.6 RNK sekvenciranje A major breakthrough (replaced microarrays) in the late 00’s and has been widely used since. Uses next-generation sequencing (NGS) to reveal the presence and quantity of RNA in a biological sample at a given moment. Able to detect novel (undiscovered) isoforms and has a broader dynamic range compapred to microarrays. Procedura izolacije RNK je nesto zahtevnija od procudere izolovanja DNK, najvise zbog otpornosti ribunukleaza (RNAza) - enzima koji razlažu fosfodiestarske veze između susednih nukleotida u RNK lancu i koji se oslobađaju kada dođe do degradacije ćelija, ali ih ima i u našem okruženju. Neke se oslobađaju i sa ljudske kože, pa su glavni izvor RNaza sami istraživači. Most of the RNA in a cell is ribosomal RNA (an RNA component of ribosome which is approx 60% rRNA and 40% protein). This is an issue since most scientists (and enthusiasts like us) will be interested in mRNA because of its protein coding function. Istrazivace najcesce interesuje informaciona RNK koja je zastupljena sa tek oko ~5% u ćelijama sisara, pa ju je potrebno selektovati iz izolovanog uzorka RNK ili selektivno denaturisati ribozomalnu RNK koja je ubedljivo najzastupljenija. To make the RNA suitable for RNA-seq it is typically fragmented and then the quality and fragmentation are assessed. 1.7 DNK mikročip (microarray) U upotrebi od kasnih 80ih, DNK mikročip je mikroskopski slajd na kojem je matrica sa više hiljada polja. Svako polje sadrži nekoliko pikomola specifične DNK sekvence - probe, koje detektuju gensku ekspresiju. Molekuli RNA uzorka su obelezeni floroscentnim probama. Ovi molekuli se vezuju za sebi komplementarne probe na mikročipu u procesu koji se zove hibridizacija. Ocitavanjem nivoa svetlosti emitovane iz svakog polja odredjuje se relativna zastupljenost te sekvence u uzorku. 1.8 Literatura Molekularna biologija 1; Dušanka Savić-Pavićević, Gordana Matić; NNK International, 2020 RNA-seqlopedia; Cresko Lab, University of Oregon Khan Academy ima odlicnu ilustraciju citavog procesa transkripcije ovde↩︎ Kodon = niz od 3 susedna nukleotida. Triplet je i najkraci niz nukleotida koji moze da kodira 20 razlicitih aminokiselina jer je \\(4^{3}&gt;20\\).↩︎ "],["poravnanje.html", "2 Poravnanje 2.1 Alignment challenges 2.2 Tophat2 algorithm 2.3 Alignment file", " 2 Poravnanje * Ovo poglavlje je adaptirano iz rada koji opisuje TopHat2 aligner. 2.1 Alignment challenges The first step in the analysis process is to map the RNA-Seq reads against the reference genome, which provides the location from which the reads originated. In contrast to DNA-Seq alignment, RNA-Seq mapping algorithms have two additional challenges: Because genes contain introns, and because reads sequenced from mature mRNA transcripts do not include these introns, any RNA-Seq alignment algorithm must be able to handle gapped (or spliced) alignment with very large gaps. In mammalian genomes, introns span a very wide range of lengths, typically from 50 to 100,000 bases, which the alignment algorithm must accommodate. The presence of processed pseudogenes, from which some or all introns have been removed, may cause many exon-spanning reads to map incorrectly. This is particularly acute for the human genome, which contains over 14,000 pseudogenes. Pseudogeni su nefunkcionalni srodnici gena koji su izgubili sposobnost kodiranja proteina ili više ne bivaju izraženi u ćeliji. Mada neki od njih nemaju introne ili promotere (to su najčešće pseudogeni koji su kopirani sa mRNA i inkorporirani nazad u hromozome, poznati kao obrađeni/processed pseudogeni). Oni se smatraju nefunkcionalnim zbog njihovog nedostatka sposobnosti da kodiraju proteine, što je posledica raznih genetičkih oštećenja (prerani stop kodoni, pomeranja okvira čitanja, ili odsustva transkripcije), ili zbog njihove nesposobnosti da kodiraju RNA (kao kod rRNA pseudogena). Pseudogeni se generalno smatraju zadnjom stanicom genomskog materijala koja može biti uklonjena iz genoma, te se često obeležavaju kao junk DNA. Some numbers (Ensembl GRCh37 gene annotations, release 66 from 2012): average length of a mature mRNA transcript in the human genome is 2,227 bp. average exon length is 235 bp. average number of exons per transcript is 9.5. Assuming that sequencing reads are uniformly distributed along a transcript, we would expect 33 to 38% of 100 bp reads from an RNA-Seq experiment to span two or more exons. Note that this proportion increases significantly as read length increases. More important for the alignment problem is that around 20% of junction-spanning reads extend by 10 bp or less into one of the exons they span. A read extending a few bases into the flanking exon can be aligned to the intron instead of the exon. A read spanning multiple exons from genes with processed pseudogene copies can be aligned to the pseudogene copies instead of the gene from which it originates. How Tophat2 handles these issues: If a read extends only a few bases into one of two adjacent exons, then it often happens that the read will align equally well, but incorrectly, with the sequence of the intervening intron. To handle this problem, the appropriate algorithm detects potential splice sites for introns (GT-AG, GC-AG, and AT-AC). It uses these candidate splice sites in a subsequent step to correctly align multiexon-spanning reads. Concerning the human genome, for which there are relatively comprehensive annotations of protein-coding genes, the annotations can be used to map reads more accurately by aligning the reads preferentially to real genes rather than pseudogenes. 2.2 Tophat2 algorithm Given RNA-Seq reads as input, TopHat2 begins by mapping reads against the known transcriptome (if available). TopHat2 aligns unmapped reads against the genome. Any reads contained entirely within exons will be mapped, whereas other spanning introns may not be. Tophat interno koristi Bowtie aligner (od istih autora) za klasičan alignment. The unmapped reads are split into smaller non-overlapping segments (25 bp each by default) which are then aligned against the genome. Tophat2 examines any cases in which the left and right segments of the same read are mapped within a user-defined maximum intron size (usually between 50 and 100,000 bp). When this pattern is detected, TopHat2 re-aligns the entire read sequence to that genomic region in order to identify the most likely location of the splice site. It pays attention to the known junction signals (GT-AG, GC-AG, and AT-AC). The resulting spliced sequences are collected as a set of potential transcript fragments. Any reads not mapped in the previous stages (or mapped very poorly) are then re-aligned against this novel transcriptome. After these steps, some of the reads may have been aligned incorrectly by extending an exonic alignment a few bases into the adjacent intron. TopHat2 checks if such alignments extend into the introns identified in the split-alignment phase; if so, it can realign these reads to the adjacent exons instead. In the final stage, TopHat2 divides the reads into those with unique alignments and those with multiple alignments. For the multi-mapped reads, TopHat2 gathers statistical information (for example, the number of supporting reads) about the relevant splice junctions, insertions, and deletions, which it uses to recalculate the alignment score for each read. Based on these new alignment scores, TopHat2 reports the most likely alignment locations for such multi-mapped reads. For paired-end reads, TopHat2 processes the two reads separately through the same mapping stages described above. In the final stage, the independently aligned reads are analyzed together to produce paired alignments, taking into consideration additional factors including fragment length and orientation. 2.3 Alignment file CIGAR: a string describing how the read aligns with the reference. It consists of one or more components. Each component comprises an operator and the number of bases which the operator applies to. Operators are: MIDNSHP=X. https://broadinstitute.github.io/picard/explain-flags.html pysam is a Python package that wraps the functionality of the Samtools toolkit and enables many useful manipulations of SAM/BAM files. cigar types in pysam: 0 - alignment match (can be a sequence match or mismatch) 1 - insertion to the reference; 2 - deletion from the reference 3 - skipped region from the reference 4 - soft clipping (clipped sequences present in SEQ) 5 - hard clipping (clipped sequences NOT present in SEQ) 6 - padding (silent deletion from padded reference) 7 - sequence match 8 - sequence mismatch import pysam bamfile = pysam.AlignmentFile(&quot;/opt/aligned/sample_03_accepted_hits.bam&quot;, &quot;rb&quot;) for read in bamfile.fetch(): for (cigarType, cigarLength) in read.cigar: if cigarType == 3: print(read.cigar) print(read) break else: continue break ## [(0, 96), (3, 8645), (0, 4)] ## read56 99 0 87263 50 96M8645N4M 0 96010 100 CNGGGTGATCACTCAGAAGAAAAGGTGAATACCGGATGTTGTAAGCTATTGAACTGCCACAAGTGATATCTTTACACACCATTCTGCTGTCATAGGGTAG array(&#39;B&#39;, [40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40]) [(&#39;AS&#39;, -5), (&#39;XN&#39;, 0), (&#39;XM&#39;, 2), (&#39;XO&#39;, 0), (&#39;XG&#39;, 0), (&#39;NM&#39;, 2), (&#39;MD&#39;, &#39;1G91T6&#39;), (&#39;YT&#39;, &#39;UU&#39;), (&#39;XS&#39;, &#39;+&#39;), (&#39;NH&#39;, 1)] bamfile.close() "],["kvantifikacija.html", "3 Kvantifikacija 3.1 Motivation for RNA-Seq quantification 3.2 RNA-Seq quantification 3.3 Gene level quantification 3.4 (Within-sample) Normalization", " 3 Kvantifikacija import time import pandas as pd import pysam 3.1 Motivation for RNA-Seq quantification Typical studies: DNA-Seq -&gt; alignment -&gt; variant calling -&gt; genome wide association study (GWAS); RNA-Seq -&gt; alignment -&gt; quantification -&gt; differential expression analysis 3.2 RNA-Seq quantification Pod pojmom kvantifikacije, u kontekstu RNA-Seq analize, podrazumevamo procenu relativne zastupljenosti mRNA molekula u uzorku. Counting versus probabilistic estimation dilemma is (mostly) about doing analysis on gene versus transcript level. - When quantifying on gene level - we simply count the number of reads aligned to each gene. - On transcript level, we need an algorithm such as the Expectation Maximization (EM, pictured below) to deal with the uncertainty. When performing statistical analysis of RNA expression, doing it on gene level compared to transcript level is more robust and experimentally actionable. The biologists will also usually draw their conclusions on gene level since that’s the level that the biological pathways are annotated on. However, the use of gene counts for statistical analysis can mask transcript-level dynamics. A popular alternative nowadays is to estimate the transcript abundances and then aggregate to gene level, or perform the entire analysis on trancsript level (testing for differential expression) and then aggregate the results. 3.3 Gene level quantification We shall, for simplicity’s sake, only perform gene level quantification. Even though it has some drawbacks, it’s a strategy still used by most genomic scientists. Here’s what we have at the beginning of the quantification step and what we want to estimate: We have: aligned reads and annotations. A file format called SAM/BAM is now the standard formats for next-generation sequence alignments. We estimate: relative abundance. We’ll start with some simple methods to find if two intervals overlap. def overlap(x, y): &quot;&quot;&quot; This function takes two intervals and determines whether they have any overlapping segments. &quot;&quot;&quot; new_start = max(x[1], y[1]) new_end = min(x[2], y[2]) if new_start &lt; new_end and x[0] == y[0]: return True return False We will define four intervals as tuples. region1 = (&quot;chr3&quot;, 27, 82) region2 = (&quot;chr4&quot;, 27, 82) region3 = (&quot;chr3&quot;, 57, 75) overlap(region1, region2) ## False overlap(region1, region3) ## True We shall now pick a gene of interest and try to find reads mapping to that gene. # the location of DEFB125 gene in human genome, gencode.v27 annotation gene = (&#39;chr20&#39;, 87249, 97094) To start exploring reads from a SAM/BAM file, we first need to load the file. # load BAM file bamfile = pysam.AlignmentFile(&quot;/opt/aligned/sample_01_accepted_hits.bam&quot;, &quot;rb&quot;) Note the ‘rb’ parameter indicates to read the file as binary, which is the BAM format (BAM stands for Binary Alignment Map). If loading a SAM file, this parameter does not need to be specified. An important and very common application is to count the number of reads (aligned fragments) that overlap a given feature (i.e. region of the genome or gene). One simple approach to doing this is to make a list of all reads generated and simply iterate over the reads to identify whether a read overlaps a region. In this case we need an overlap method that can compare a simple interval (defined by a tuple of sequence, start, end) with a pysam AlignedSegment object. This overlap method also needs the AlignmentFile object to decode the chromosome name. def overlap(x, gene, bamfile): &quot;&quot;&quot; A modified version of overlap that takes an interval and a pysam AlignedSegment and tests for overlap &quot;&quot;&quot; new_start = max(x.reference_start, gene[1]) new_end = min(x.reference_end, gene[2]) if (new_start &lt; new_end and bamfile.getrname(x.tid) == gene[0]): return True return False start_time = time.time() # code to iterate over reads and count for a single gene naive_gene_count = 0 for x in bamfile.fetch(): # Note x is of type pysam.AlignedSegment if(overlap(x, gene, bamfile)): naive_gene_count += 1 print(&quot;--- %s seconds ---&quot; % (time.time() - start_time)) ## --- 2.245061159133911 seconds --- print(naive_gene_count) ## 1016 The problem with this approach is that to do this, you will need to store the entire file in memory. Worse than that, in order to find the reads within a single gene, you would need to iterate over the entire file, which can contain hundreds of millions of reads. This is quite slow even for a single gene, but will only increase if you want to look at many genes. Instead, more efficient datastructures (and indexing schemes) can be used to retrieve reads based on positions in more efficient ways. To get the reads overlapping a given region, Pysam has a method called fetch(), which takes the genomic coordinates and returns an iterator of all reads overlapping that region. bam_iter = bamfile.fetch(gene[0], gene[1], gene[2]) start_time = time.time() pysam_gene_count = 0 for x in bam_iter: pysam_gene_count += 1 print(&quot;--- %s seconds ---&quot; % (time.time() - start_time)) ## --- 0.027565956115722656 seconds --- print(pysam_gene_count) ## 1016 Not surprisingly, they are the same - the big difference is that the second method is significantly faster. The reason for this is that Pysam (like Samtools, Picard, and other similar toolkits) make use of clever tricks to index the file by genomic positions to more efficiently search for reads within a given genomic interval. Now that we know how to count reads overlapping a region, we can write this as a function and try and compute this for all genes. def read_count(gene, bamfile): &quot;&quot;&quot; Compute the number of reads contained in a bamfile that overlap a given interval &quot;&quot;&quot; bam_iter = bamfile.fetch(gene[0], gene[1], gene[2]) pysam_gene_count = 0 for x in bam_iter: pysam_gene_count += 1 return pysam_gene_count You can run this with any gene tuple now: # the location of ZNFX1 gene in human genome, gencode.v27 annotation gene2 = (&quot;chr20&quot;, 49237945, 49278426) read_count(gene2, bamfile) ## 5282 Now, let’s compute the gene counts for all genes. We’ll start by reading in all genes: start_time = time.time() gene_counts={} with open(&#39;/opt/gencode.v27.chr20.bed&#39;, &#39;r&#39;) as f: for line in f: tokens = line.split(&#39;\\t&#39;) gene_local = (tokens[0], int(tokens[1]), int(tokens[2])) count = read_count(gene_local, bamfile) gene_counts.update({tokens[3].rstrip() : count}) print(&quot;--- %s seconds ---&quot; % (time.time() - start_time)) ## --- 1.477412462234497 seconds --- Now it’s easy to query the gene counts for different genes. print(gene_counts.get(&quot;ARFGEF2&quot;)) ## 7283 print(gene_counts.get(&quot;SOX12&quot;)) ## 3836 print(gene_counts.get(&quot;WFDC8&quot;)) ## 1641 3.4 (Within-sample) Normalization In previous slides, we’ve seen how we can compute raw counts, i.e. number of reads that align to a particular feature (gene or transcript). \\[X_{i}\\] These numbers are heavily dependent on two things: - The amount of fragments sequenced - The length of the feature, or more appropriately, the effective length. Effective length refers to the number of possible start sites a feature could have generated a fragment of that particular length. In practice, the effective length is usually computed as: \\[\\widetilde{l_{i}}=l_{i}-\\mu_{FLD}+1\\] Since counts are NOT scaled by the length of the feature, all units in this category are not comparable within a sample without adjusting for the feature length! 3.4.1 Different units Reads Per Kilobase per Million reads mapped (RPKM), or for the paired-end reads: FPKM (Fragments instead of Reads). \\[FPKM_{i}=\\frac{X_i}{\\left ( \\frac{\\widetilde{l_{i}}}{10^{3}}\\left ( \\frac{N}{10^{6}} \\right ) \\right )} = \\frac{X_i}{\\widetilde{l_{i}}N}\\cdot 10^{9}\\] Transcripts Per Million (TPM) \\[TPM_{i}=\\frac{X_i}{\\widetilde{l_{i}}}\\cdot \\left ( \\frac{1}{\\Sigma_{j}\\frac{X_j}{\\widetilde{l_{j}}}} \\right ) \\cdot 10^{6}\\] counts = {&#39;Gene Name&#39;: [&#39;A(5kb)&#39;, &#39;B(10kb)&#39;, &#39;C(1kb)&#39;, &#39;D(20kb)&#39;], &#39;Rep1 Counts&#39;: [100000, 200000, 100000, 0], &#39;Rep2 Counts&#39;: [120000, 250000, 80000, 0], &#39;Rep3 Counts&#39;: [300000, 600000, 150000, 10000] } df = pd.DataFrame(counts, columns= [&#39;Gene Name&#39;, &#39;Rep1 Counts&#39;, &#39;Rep2 Counts&#39;, &#39;Rep3 Counts&#39;]).set_index(&#39;Gene Name&#39;) df ## Rep1 Counts Rep2 Counts Rep3 Counts ## Gene Name ## A(5kb) 100000 120000 300000 ## B(10kb) 200000 250000 600000 ## C(1kb) 100000 80000 150000 ## D(20kb) 0 0 10000 Let’s first calculate the abundances in FPKM units. We first divide by the total number of reads: df_rpkm = df.div(df.sum()/1000000).round(2) df_rpkm ## Rep1 Counts Rep2 Counts Rep3 Counts ## Gene Name ## A(5kb) 250000.0 266666.67 283018.87 ## B(10kb) 500000.0 555555.56 566037.74 ## C(1kb) 250000.0 177777.78 141509.43 ## D(20kb) 0.0 0.00 9433.96 Then we normalize for gene length: # save gene sizes in new column df_rpkm[&#39;kb&#39;] = [5,10,1,20] # gene size normalization df_rpkm = df_rpkm.div(df_rpkm.kb, axis=0).round(2) df_rpkm.drop([&#39;kb&#39;], axis=1) ## Rep1 Counts Rep2 Counts Rep3 Counts ## Gene Name ## A(5kb) 50000.0 53333.33 56603.77 ## B(10kb) 50000.0 55555.56 56603.77 ## C(1kb) 250000.0 177777.78 141509.43 ## D(20kb) 0.0 0.00 471.70 The sums of total normalized counts in each column are not equal as we prove below: # FPKM normalization sums per samples are not equal (samples are not comparable). df_rpkm.drop([&#39;kb&#39;], axis=1).sum() ## Rep1 Counts 350000.00 ## Rep2 Counts 286666.67 ## Rep3 Counts 255188.67 ## dtype: float64 Now we will calculate the abundances in TPM units. Here, the first thing we do is normalize for gene length! df_tpm = df # save gene sizes in new column df_tpm[&#39;kb&#39;] = [2,4,1,10] # gene size normalization is performed first df_tpm = df_tpm.div(df_tpm.kb, axis=0).round(2) df_tpm.drop([&#39;kb&#39;], axis=1) ## Rep1 Counts Rep2 Counts Rep3 Counts ## Gene Name ## A(5kb) 50000.0 60000.0 150000.0 ## B(10kb) 50000.0 62500.0 150000.0 ## C(1kb) 100000.0 80000.0 150000.0 ## D(20kb) 0.0 0.0 1000.0 And now we perform the library size normalization, using abundances already normalized for gene length: # library size normalization (division by 10 instead of 10^6) df_tpm = df_tpm.div(df_tpm.sum()/1000000).round(3) df_tpm.drop([&#39;kb&#39;], axis=1) ## Rep1 Counts Rep2 Counts Rep3 Counts ## Gene Name ## A(5kb) 250000.0 296296.296 332594.235 ## B(10kb) 250000.0 308641.975 332594.235 ## C(1kb) 500000.0 395061.728 332594.235 ## D(20kb) 0.0 0.000 2217.295 The sums of total normalized counts in each column are now equal (when using TPM)! # TPM normalization sums per samples are equal (samples are comparable). df_tpm.drop([&#39;kb&#39;], axis=1).sum() ## Rep1 Counts 1000000.000 ## Rep2 Counts 999999.999 ## Rep3 Counts 1000000.000 ## dtype: float64 def tpm(genefile, bamfile): &quot;&quot;&quot; Compute the TPM (transcripts per million) metric for all genes within the genefile using an RNA-Seq bamfile &quot;&quot;&quot; total_mapped_reads = 0 # here you want all reads bam_iter = bamfile.fetch() for x in bam_iter: total_mapped_reads += 1 gene_counts = {} with open(genefile, &#39;r&#39;) as f: for line in f: tokens = line.split(&#39;\\t&#39;) gene_local = (tokens[0], int(tokens[1]), int(tokens[2])) gene_length = gene_local[2] - gene_local[1] raw_count = read_count(gene_local, bamfile) if tokens[3] in gene_counts: gene_counts[tokens[3]] = (gene_counts[tokens[3]][0] + raw_count, gene_length) else: gene_counts.update({tokens[3].rstrip() : (raw_count, gene_length)}) countsDF = pd.DataFrame(gene_counts, index=[&#39;raw_count&#39;, &#39;gene_length&#39;]) countsDF = countsDF.T X=countsDF.iloc[:,0].values l=countsDF.iloc[:,1].values countsDF = countsDF.assign(tpm = 1e6 * (X/l) / (X/l).sum()) return(countsDF) start_time = time.time() gene_counts = tpm(&#39;/opt/gencode.v27.chr20.bed&#39;, bamfile) print(&quot;--- %s seconds ---&quot; % (time.time() - start_time)) ## --- 2.403627634048462 seconds --- gene_counts.head(10) ## raw_count gene_length tpm ## DEFB125 1016 9845 162.980261 ## DEFB126 559 3383 260.955726 ## DEFB127 419 1694 390.622844 ## DEFB128 368 1829 317.754079 ## DEFB129 395 2629 237.281309 ## DEFB132 3381 3361 1588.669944 ## AL034548.1 1218 1672 1150.450762 ## C20orf96 1035 19916 82.072045 ## ZCCHC3 2748 3354 1293.929728 ## NRSN2-AS1 4344 27912 245.785286 def rpkm(genefile, bamfile): &quot;&quot;&quot; Compute the RPKM (reads per kilobase per million mapped reads) metric for all genes within the genefile using an RNA-Seq bamfile &quot;&quot;&quot; total_mapped_reads = 0 # here you want all reads bam_iter = bamfile.fetch() for x in bam_iter: total_mapped_reads += 1 gene_counts = {} with open(genefile, &#39;r&#39;) as f: for line in f: tokens = line.split(&#39;\\t&#39;) gene_local = (tokens[0], int(tokens[1]), int(tokens[2])) gene_length=gene_local[2]-gene_local[1] raw_count = read_count(gene_local, bamfile) rpk_metric = 1e9 * raw_count \\ / (total_mapped_reads * gene_length) gene_counts.update({tokens[3].rstrip() : (raw_count, gene_length, rpk_metric)}) countsDF = pd.DataFrame(gene_counts, index=[&#39;raw_count&#39;, &#39;gene_length&#39;, &#39;rpkm&#39;]) countsDF = countsDF.T return(countsDF) start_time = time.time() gene_counts_rpkm = rpkm(&#39;/opt/gencode.v27.chr20.bed&#39;, bamfile) print(&quot;--- %s seconds ---&quot; % (time.time() - start_time)) ## --- 2.5323965549468994 seconds --- gene_counts_rpkm.head(10) ## raw_count gene_length rpkm ## DEFB125 1016.0 9845.0 61.832560 ## DEFB126 559.0 3383.0 99.003158 ## DEFB127 419.0 1694.0 148.197152 ## DEFB128 368.0 1829.0 120.551704 ## DEFB129 395.0 2629.0 90.021397 ## DEFB132 3381.0 3361.0 602.720410 ## AL034548.1 1218.0 1672.0 436.465836 ## C20orf96 1035.0 19916.0 31.137051 ## ZCCHC3 2748.0 3354.0 490.899862 ## NRSN2-AS1 4344.0 27912.0 93.247694 "],["dekspresija.html", "4 Diferencijalna ekspresija 4.1 Diferencijalna Eskpresija 4.2 Between-sample normalization 4.3 Exploratory analysis 4.4 Intro to statistical inference 4.5 Central Limit Theorem 4.6 The t-distribution 4.7 Multiple testing", " 4 Diferencijalna ekspresija library(Biobase) library(DESeq2) library(broom) library(MASS) library(ggplot2) import pysam from scipy import stats # import matplotlib.pyplot as plt import glob import os import pandas as pd import numpy as np def read_count(gene, bamfile): &quot;&quot;&quot; Compute the number of reads contained in a bamfile that overlap a given interval &quot;&quot;&quot; bam_iter = bamfile.fetch(gene[0], gene[1], gene[2]) pysam_gene_count = 0 for x in bam_iter: pysam_gene_count += 1 return pysam_gene_count paths = glob.glob(&quot;/opt/aligned/*.bam&quot;) paths ## [&#39;/opt/aligned/sample_07_accepted_hits.bam&#39;, &#39;/opt/aligned/sample_10_accepted_hits.bam&#39;, &#39;/opt/aligned/sample_03_accepted_hits.bam&#39;, &#39;/opt/aligned/sample_09_accepted_hits.bam&#39;, &#39;/opt/aligned/sample_02_accepted_hits.bam&#39;, &#39;/opt/aligned/sample_05_accepted_hits.bam&#39;, &#39;/opt/aligned/sample_01_accepted_hits.bam&#39;, &#39;/opt/aligned/sample_06_accepted_hits.bam&#39;, &#39;/opt/aligned/sample_04_accepted_hits.bam&#39;, &#39;/opt/aligned/sample_08_accepted_hits.bam&#39;] counts = [] samples = [] for path in paths: sname = os.path.basename(path).replace(&#39;_accepted_hits.bam&#39;, &#39;&#39;) bamfile = pysam.AlignmentFile(path) gene_counts={} with open(&#39;/opt/gencode.v27.chr20.bed&#39;, &#39;r&#39;) as f: for line in f: tokens = line.split(&#39;\\t&#39;) current_gene = (tokens[0], int(tokens[1]), int(tokens[2])) count = read_count(current_gene, bamfile) gene_counts.update({tokens[3].rstrip() : count}) counts.append(gene_counts) samples.append(sname) df = pd.DataFrame.from_dict(counts) df.index = samples df = df.sort_index().T df.head(10) ## sample_01 sample_02 sample_03 ... sample_08 sample_09 sample_10 ## DEFB125 1016 465 1146 ... 1260 285 426 ## DEFB126 559 223 555 ... 749 132 240 ## DEFB127 419 145 527 ... 720 114 218 ## DEFB128 368 143 458 ... 457 87 138 ## DEFB129 395 188 573 ... 730 144 186 ## DEFB132 3381 1522 4193 ... 2012 516 711 ## AL034548.1 1218 572 1554 ... 3932 889 1037 ## C20orf96 1035 385 1384 ... 1815 295 403 ## ZCCHC3 2748 1150 2804 ... 3683 814 1023 ## NRSN2-AS1 4344 1921 5404 ... 5986 1337 1737 ## ## [10 rows x 10 columns] df.shape ## (1357, 10) KiR = np.exp((np.log(df)).mean(axis=1)) #geometric mean df = df[(KiR != 0).values] KiR = KiR[(KiR != 0).values] df.shape ## (1347, 10) 4.1 Diferencijalna Eskpresija Gen ili transkript nazivamo diferencijalno ekspresovanim ako je uocena statisticki znacajna promena u ekspresiji izmedju neke dve grupe uzoraka koje posmatramo. Otkrivanje diferencijalno ekspresovanih gena je cesto cilj statisticke analize RNK sekvenciranih podataka. 4.2 Between-sample normalization The general point of between-sample normalization (BSN) is to be able to compare expression features (genes, transcripts) ACROSS experiments. This is not to be confused with within-sample normalization methods (comparing different features within a single sample). Most BSN methods address two issues : Variable sequencing depth (the total number of reads sequenced) between experiments. Finding a “control set” of expression features which should have relatively similar expression patterns across experiments (e.g. genes that are not differentially expressed) to serve as a baseline. Harold Pimentel: In RNA-Seq, 2 != 2: Between-sample normalization One way to do the total count normalization would be to divide by the total counts : Gene Control Counts Treatment Counts Control Normalized Treatment Normalized G1 2.00 6.00 0.20 0.06 G2 2.00 6.00 0.20 0.06 G3 2.00 6.00 0.20 0.06 G4 2.00 6.00 0.20 0.06 FG 2.00 76.00 0.20 0.76 If one compares the control and treatment proportions, it seems that every gene is differentially expressed. We are typically under the assumption that the majority of the genes do not change in expression. Under that assumption, it is much more plausible that genes one through four remain equally expressed, whereas “funky gene” (FG) is the only differentially expressed gene. We might consider normalizing by the sum of the total counts while omitting the last gene since its highly overexpressed and is throwing off the normalization : Gene Control Counts Treatment Counts Control Normalized Treatment Normalized G1 2.00 6.00 0.25 0.25 G2 2.00 6.00 0.25 0.25 G3 2.00 6.00 0.25 0.25 G4 2.00 6.00 0.25 0.25 FG 2.00 76.00 0.25 3.17 Between sample normalization procedures estimate sample-specific normalization factors that are used to rescale the observed counts. Using these normalization methods, the sum of the normalized counts across all genes are therefore not necessarily equal between samples (as it would be if only the library sizes were used for normalization), but the goal is instead to make the normalized counts for non-differentially expressed genes similar between the samples. Popular examples of these normalization procedures are TMM (trimmed mean of M-values) and DESeq. These two methods perform similarly and are both based on an assumption that most genes are equivalently expressed in the samples, and that the differentially expressed genes are divided more or less equally between up- and downregulation. With DESeq sample-specific normalization constants are estimated with the median-of-ratios method: Let’s try estimating sample specific normalization factor for the two dummy samples from the example. We first calculate the geometric means for each gene: Gene Control Counts Treatment Counts KiR G1 2.00 6.00 3.464 G2 2.00 6.00 3.464 G3 2.00 6.00 3.464 G4 2.00 6.00 3.464 FG 2.00 76.00 12.329 Next we divide each count with the geometric mean expression for that gene: Gene Control Counts/KiR Treatment Counts/KiR G1 0.57735 1.73205 G2 0.57735 1.73205 G3 0.57735 1.73205 G4 0.57735 1.73205 FG 0.16222 6.16441 - It is obvious that sample specific normalization factors are 0.57735 and 1.73205 (sample medians). Finally we divide each sample by its normalization factor: Gene Control Normalized Treatment Normalized G1 3.4641 3.4641 G2 3.4641 3.4641 G3 3.4641 3.4641 G4 3.4641 3.4641 FG 3.4641 43.87864 aux = df.divide(KiR.values, axis = 0) aux.head(10) ## sample_01 sample_02 sample_03 ... sample_08 sample_09 sample_10 ## DEFB125 1.351510 0.618555 1.524440 ... 1.676086 0.379115 0.566677 ## DEFB126 1.411339 0.563021 1.401240 ... 1.891043 0.333268 0.605942 ## DEFB127 1.268995 0.439151 1.596087 ... 2.180612 0.345264 0.660241 ## DEFB128 1.450690 0.563719 1.805478 ... 1.801536 0.342962 0.544009 ## DEFB129 1.049116 0.499326 1.521882 ... 1.938873 0.382463 0.494014 ## DEFB132 1.840957 0.828730 2.283092 ... 1.095536 0.280962 0.387140 ## AL034548.1 0.854659 0.401367 1.090427 ... 2.759048 0.623803 0.727653 ## C20orf96 1.276008 0.474650 1.706276 ... 2.237638 0.363693 0.496842 ## ZCCHC3 1.376184 0.575914 1.404228 ... 1.844427 0.407647 0.512313 ## NRSN2-AS1 1.335328 0.590508 1.661168 ... 1.840072 0.410988 0.533947 ## ## [10 rows x 10 columns] sizeF = aux.median(axis = 0).values normdf = df.divide(sizeF, axis = 1) Normalized, this is how our simulated dataset looks like: normdf.head(10) ## sample_01 sample_02 ... sample_09 sample_10 ## DEFB125 799.307029 844.137999 ... 708.873105 816.735707 ## DEFB126 439.776210 404.823169 ... 328.320175 460.132793 ## DEFB127 329.635478 263.225828 ... 283.549242 417.953953 ## DEFB128 289.512782 259.595127 ... 216.392842 264.576356 ## DEFB129 310.754209 341.285901 ... 358.167463 356.602914 ## DEFB132 2659.898687 2762.963514 ... 1283.433410 1363.143399 ## AL034548.1 958.224372 1038.380506 ... 2211.186631 1988.157109 ## C20orf96 814.254700 698.909956 ... 733.745845 772.639648 ## ZCCHC3 2161.905233 2087.653115 ... 2024.641077 1961.316029 ## NRSN2-AS1 3417.509582 3487.288378 ... 3325.485406 3330.211088 ## ## [10 rows x 10 columns] 4.3 Exploratory analysis Data quality assessment and quality control (i.e. the removal of insufficiently good data) are essential steps of any data analysis. These steps should typically be performed very early in the analysis of a new data set, preceding or in parallel to the differential expression testing. The dataset we are investigating is simulated, but let us pretend that samples 6 through 10 are coming from the “treated” population and that samples 1 through 5 are “untreated” or “control” samples. A useful initial step in an RNA-seq analysis is often to assess overall similarity between samples: Which samples are similar to each other, which are different? Does this fit to the expectation from the experiment’s design? What are the major sources of variation in the dataset? To explore the similarity of our samples, we will be performing sample-level QC using Principal Component Analysis (PCA) and hierarchical clustering methods. Our sample-level QC allows us to see how well our replicates cluster together, as well as, observe whether our experimental condition represents the major source of variation in the data. Performing sample-level QC can also identify any sample outliers, which may need to be explored further to determine whether they need to be removed prior to DE analysis. from sklearn.decomposition import PCA pca = PCA(n_components=2) principalComponents = pca.fit_transform(normdf.T) principalDf = pd.DataFrame(data = principalComponents , columns = [&#39;principal component 1&#39;, &#39;principal component 2&#39;]) categories = np.array([&quot;untreated&quot;, &quot;treated&quot;]) finalDf = pd.concat([principalDf, pd.DataFrame(np.repeat(categories, [5, 5], axis=0), columns=[&#39;condition&#39;])], axis = 1) finalDf ## principal component 1 principal component 2 condition ## 0 7253.669019 -1133.085852 untreated ## 1 6777.834829 -351.825929 untreated ## 2 6777.584161 1550.295036 untreated ## 3 6891.705861 -334.630787 untreated ## 4 7100.443338 351.964060 untreated ## 5 -7020.208240 2833.669670 treated ## 6 -7027.034271 -2662.133319 treated ## 7 -7052.228614 957.489013 treated ## 8 -6578.866744 -1450.586265 treated ## 9 -7122.899341 238.844374 treated pcaDF &lt;- reticulate::py$finalDf pcaDF ## principal component 1 principal component 2 condition ## 1 7253.669 -1133.0859 untreated ## 2 6777.835 -351.8259 untreated ## 3 6777.584 1550.2950 untreated ## 4 6891.706 -334.6308 untreated ## 5 7100.443 351.9641 untreated ## 6 -7020.208 2833.6697 treated ## 7 -7027.034 -2662.1333 treated ## 8 -7052.229 957.4890 treated ## 9 -6578.867 -1450.5863 treated ## 10 -7122.899 238.8444 treated ggplot(pcaDF, aes(x=`principal component 1`, y=`principal component 2`, color = condition)) + geom_point() 4.4 Intro to statistical inference For each gene, we are interested in differences in mean expression between the two sample groups. import seaborn as sns aux = {&quot;norm&quot; : normdf.loc[&#39;AL031055.1&#39;], &quot;group&quot; : np.repeat(categories, [5, 5], axis=0)} df = pd.DataFrame(data=aux) sns.stripplot(x=&quot;group&quot;, y=&quot;norm&quot;, data=df, jitter=True).set_title(&#39;AL031055.1&#39;) aux = {&quot;norm&quot; : normdf.loc[&#39;AL023803.2&#39;], &quot;group&quot; : np.repeat(categories, [5, 5], axis=0)} df = pd.DataFrame(data=aux) sns.stripplot(x=&quot;group&quot;, y=&quot;norm&quot;, data=df, jitter=True).set_title(&#39;AL023803.2&#39;) sns.boxplot(x=&quot;group&quot;, y=&quot;norm&quot;, data=df).set_title(&#39;AL023803.2&#39;) cMean = normdf.loc[&#39;AL023803.2&#39;][0:5].mean() tMean = normdf.loc[&#39;AL023803.2&#39;][5:10].mean() print(cMean) ## 354.8722544056803 print(tMean) ## 402.20746388364734 diff = tMean - cMean diff ## 47.335209477967055 So the expression level for AL023803.2 in treated samples is about 10% higher. But these averages are random variables. They can take many values. If we repeat the experiment, by sequencing samples from a new batch of patients (or even resequencing the same ones) we get different means. Every time we repeat this experiment, we get a different value of mean difference. When comparing measured values we need to be skeptical. How do we know that this difference is due to the treatment? What happens if compare two sets of untreated samples? Will we see a difference this big? Statisticians refer to this scenario as the null hypothesis. The name “null” is used to remind us that we are acting as skeptics: we give credence to the possibility that there is no difference. So what do we do? Because we do not have access to entire populations of untreated and treated samples, we cannot confidently say just by comparing the mean expression values that a gene is differentialy expressed. We can perform a simple permutation test. Permutation tests take advantage of the fact that if we randomly shuffle the treated and untreated labels for the 10 measurements that we have - then the null is true. So we shuffle the labels, calculate the mean difference and assume that the ensuing distribution approximates the null distribution. Here is how we generate a null distribution by shuffling the data 1,000 times: normexp = normdf.loc[&#39;AL023803.2&#39;] np.random.seed(6) means =[] for i in range(1000) : aux = np.random.permutation(normexp) cmean = aux[0:5].mean() tmean = aux[5:10].mean() means.append(tmean-cmean) betaHat &lt;- reticulate::py$diff b1 &lt;- unlist(reticulate::py$means) hist(b1, breaks = 50) abline(v=c(betaHat, -betaHat), col = &quot;red&quot;) # sum(abs(b1) &gt; abs(betaHat))/length(b1) absmeans = [abs(x) for x in means] absdiff = abs(diff) p = sum(absmeans &gt; absdiff)/len(absmeans) p ## 0.135 Null hypothesis: there is no significant difference between specified populations, any observed difference being due to sampling or experimental error. The p-value is defined as the probability of obtaining a result equal to or “more extreme” than what was actually observed, when the null hypothesis is true. The alternative hypothesis is considered true if the statistic observed would be an unlikely realization of the null hypothesis according to the p-value. 4.5 Central Limit Theorem CLT: When the sample size is large, the average \\(\\bar{Y}\\) of a random sample follows a normal distribution centered at the population average \\(\\mu_{Y}\\) and with standard deviation equal to the population standard deviation \\(\\sigma_{Y}\\), divided by the square root of the sample size \\(N\\). We refer to the standard deviation of the distribution of a random variable as the random variable’s standard error. https://rajeshrinet.github.io/blog/2014/central-limit-theorem/ Population mean and variance (deviation squred) are parameters defined as: \\[\\mu_{Y} = \\frac{1}{n}\\sum_{i=1}^{n}y_{i}\\] \\[\\sigma_{Y}^2 = \\frac{1}{n}\\sum_{i=1}^{n}(y_{i}-\\mu_{Y})^{2}\\] where \\(n\\) is the number of elements in population. Normal distribution \\(N(\\mu, \\sigma)\\) is defined with the density function: \\[f(x)=\\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}e^{-\\frac{\\left (x-\\mu_{X} \\right )^{2}}{2\\sigma^{2}}}\\] If we subtract a constant from a random variable, the mean of the new random variable shifts by that constant. Mathematically, if \\(X\\) is a random variable with mean \\(\\mu\\) and \\(a\\) is a constant, the mean of \\(X − a\\) is \\(\\mu − a\\). A similarly intuitive result holds for multiplication and the standard deviation (SD). If \\(X\\) is a random variable with mean \\(\\mu\\) and SD \\(\\sigma\\), and \\(a\\) is a constant, then the mean and SD of \\(aX\\) are \\(a\\mu\\) and \\(| a | \\sigma\\) respectively. Knowing this, the CLT implies that if we take many samples of size \\(N\\), then the quantity: \\[\\frac{\\bar{Y}-\\mu_{Y}}{\\sigma_{Y}/\\sqrt{N}}\\] is approximated with a normal distribution centered at 0 and with standard deviation 1. If \\(X\\) and \\(Y\\) are two random variables independent of each other, then the variance of \\(X + Y\\) is the sum of the variances \\(\\sigma_{X}^{2} + \\sigma_{Y}^{2}\\). The sum (or the difference) of normal variables is again normal. Under the null hypothesis (when the mean difference is 0), the ratio: \\[\\frac{\\bar{Y}-\\bar{X}}{\\sqrt{\\frac{\\sigma_{Y}^{2}}{N}+\\frac{\\sigma_{X}^{2}}{M}}}\\] is approximated by a normal distribution centered at 0 and standard deviation 1. Using this approximation makes computing p-values simple because we know the proportion of the distribution under any value. For example, only 5% of these values are larger than 2 (in absolute value). However, we can’t claim victory just yet because we don’t know the population standard deviations: \\(\\sigma_{X}\\) and \\(\\sigma_{Y}\\). These are unknown population parameters, but we can get around this by using the sample standard deviations, call them \\(s_{X}\\) and \\(s_{Y}\\). These are defined as: \\[s_{X}^2 = \\frac{1}{M-1}\\sum_{i=1}^{M}(X_{i}-\\bar{X})^{2}\\] \\[s_{Y}^2 = \\frac{1}{N-1}\\sum_{i=1}^{N}(Y_{i}-\\bar{Y})^{2}\\] \\(M − 1\\), \\(N − 1\\): the degrees of freedom. So we can redefine our ratio as: \\[\\frac{\\bar{Y}-\\bar{X}}{\\sqrt{\\frac{s_{Y}^{2}}{N}+\\frac{s_{X}^{2}}{M}}}\\] The CLT tells us that when \\(M\\) and \\(N\\) are large, this random variable is normally distributed with mean 0 and SD 1. 4.6 The t-distribution The CLT relies on large samples, what we refer to as asymptotic results. When the CLT does not apply, there is another option that does not rely on asymptotic results. When the original population from which a random variable, say \\(Y\\), is sampled is normally distributed with mean 0, then we can calculate the distribution of: \\[\\sqrt{N}\\frac{\\bar{Y}-0}{\\sigma_{Y}}\\] This is the ratio of two random variables so it is not necessarily normal. The fact that the denominator can be small by chance increases the probability of observing large values. In 1908. William Sealy Gosset, an employee of the Guinness brewing company, deciphered the distribution of this random variable and published a paper under the pseudonym “Student”. The distribution is therefore called Student’s t-distribution. \\[f(t)=\\frac{\\Gamma(\\frac{\\nu+1}{2})}{\\sqrt{\\nu\\pi}\\Gamma(\\frac{\\nu}{2})}\\left (1+\\frac{t^2}{\\nu} \\right )^{-\\frac{\\nu+1}{2}}\\] where \\(\\nu\\) is the degrees of freedom. So for small sample sizes we shall be computing that same ratio: \\[\\frac{\\bar{Y}-\\bar{X}}{\\sqrt{\\frac{s_{Y}^{2}}{N}+\\frac{s_{X}^{2}}{M}}}\\] only this time we shall be comparing it to the t-distribution instead of normal. All such tests are usually called Student’s t-tests, though strictly speaking that name should only be used if the variances of the two populations are also assumed to be equal; the form of the test used when this assumption is dropped is sometimes called Welch’s t-test and that’s the one that we’ll be implementing. def welch_test(a, b): # pandas.Series.var() returns an unbiased variance estimate, normalized by N-1 by default var_a = a.var() var_b = b.var() Na = len(a) Nb = len(b) # std deviation estimate s = np.sqrt(var_a/Na + var_b/Nb) # calculate the t-statistics t = (a.mean() - b.mean())/s # degrees of freedom - Welch–Satterthwaite equation, yeah it&#39;s a bit more complicated than Na + Nb - 2 deg = (((var_a)/Na + (var_b)/Nb)**2)/ ((var_a**2)/(Na**2*(Na-1)) + (var_b**2)/(Nb**2*(Nb-1))) # p-value after comparison with the t p = 2*stats.t.sf(np.abs(t), deg) return (p) p = [(index, welch_test(row.values[0:5], row.values[5:10])) for index, row in normdf.iterrows()] res = pd.DataFrame(p, columns=[&#39;gene&#39;, &#39;pval&#39;]) res = res.set_index(&#39;gene&#39;) res.shape ## (1347, 1) res.head(6) ## pval ## gene ## DEFB125 6.449128e-01 ## DEFB126 3.094837e-01 ## DEFB127 5.164307e-01 ## DEFB128 3.106288e-03 ## DEFB129 5.639828e-01 ## DEFB132 6.687543e-07 4.7 Multiple testing In genomic studies you don’t usually fit just one regression model or calculate just one p-value. You calculate many p-values. In our simulated dataset, just from chromosome 20 (which is one of the shortest in human genome) we have 1347 genes. If you use the standard cutoff of 0.05 when calling p-value significant, you’ll know that since p-values are uniformly distributed when the null is true, about 1 out of every 20 times you’ll still call that result statistically significant, even when there is no true biological effect. np.random.seed(6) pvals =[] for i in range(20000) : firstg = np.random.normal(32, 5, 20) secondg = np.random.normal(32, 5, 20) pval = welch_test(firstg, secondg) pvals.append(pval) pvals &lt;- unlist(reticulate::py$pvals) hist(pvals, breaks = 20) res[&#39;pval&#39;].plot.hist(bins=20) Called significant Not called significant Total Null true \\(V\\) \\(n_{0} - V\\) \\(n_{0}\\) Alternative true \\(S\\) \\(n_{1} - S\\) \\(n_{1}\\) Total \\(R\\) \\(n - R\\) \\(n\\) \\(V\\) represents the number of type I errors (false positives); \\(n_{1} - S\\) represents the number of type II errors (false negatives); \\(S\\) is the number of true positives and \\(n_{0} - V\\) the number of true negatives. A multiple testing correction procedure is needed to adjust the statistical confidence measures based on the number of tests performed. Different error rates are defined for this purpose: Family wise error rate: \\[FWER = P_{r}\\left (V \\geq 1 \\right ) = 1 - P_{r}\\left (V = 0 \\right )\\] is the probability of making one or more false discoveries, or type I errors when performing multiple hypotheses tests. False discovery rate: \\[FDR=E\\left \\lfloor \\frac{V}{V+S} \\right \\rfloor\\] is the expected proportion of “discoveries” (rejected null hypotheses) that are false (incorrect rejections). Suppose 1200 out of 20,000 genes are found significant at 0.05 level (threshold \\(\\alpha = 0.05\\)). No correction: expect 0.05 * 20,000 = 1000 false positives False Discovery Rate correction: expect 0.05 * 1200 = 60 false positives Family Wise Error Rate correction: expect no false positives (probability of having at least one false positive is ≤ 0.05) Benjamini-Hochberg correction: the p-values are sorted in increasing order and the i-th p-value is considered significant if it’s less or equal to \\(\\frac{i\\alpha}{n}\\). Bonferroni correction: p-values less or equal to α/n are considered significant. res = res.sort_values(by=[&#39;pval&#39;]) m = res.shape[0] qval = np.zeros(m) for i in range(0, m): qval[i] = (res[&#39;pval&#39;][i]*m/(i+1)) res[&#39;qval&#39;] = qval alpha = 0.05 res[&#39;de&#39;] = res[&#39;qval&#39;] &lt; alpha After performing Benjamini-Hochberg (FDR) correction: res.head(6) ## pval qval de ## gene ## FLRT3 9.418961e-10 0.000001 True ## PLCG1-AS1 3.296634e-09 0.000002 True ## RBM39 3.591833e-09 0.000002 True ## TOP1 5.383997e-09 0.000002 True ## RALGAPB 5.399923e-09 0.000001 True ## RTFDC1 7.302393e-08 0.000016 True res[&#39;qval&#39;].plot.hist(bins=20) "]]
